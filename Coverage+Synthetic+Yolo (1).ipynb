{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXDcWoX-EICr"
      },
      "source": [
        "# Generalized code to prepare and combine (both synthetic and real) Image Fruad Datasets for use with YOLOv5\n",
        "## Example DB: 1. COVERAGE, 2. IEEE IFS-TC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00Fx3qF7CwZr"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wkxfF6C6UXS0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import re\n",
        "import yaml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import glob\n",
        "from random import randint\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.ops import masks_to_boxes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wev6zCN8XliA",
        "outputId": "483e3216-fba1-4465-b1c8-7eb23b531463"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFEiEBONUm0g"
      },
      "source": [
        "### Unzip/extract images and masks files (uploaded as zip files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKpim5vBDUQB"
      },
      "source": [
        "### COVERAGE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct zip upload:"
      ],
      "metadata": {
        "id": "2YmGfBxtFgfC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jx-apZ4Uqmn"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(root +'masks.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF9qUU1yFQCb"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(root + 'images.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read DB files from Drive directly (faster)"
      ],
      "metadata": {
        "id": "7e8ISNs9Fp90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path where images and masks folder(s) are located \n",
        "db_root = '/content/drive/MyDrive/IF_DBs/COVERAGE/'"
      ],
      "metadata": {
        "id": "K6nnHQBzFjRL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### set name of DB, test/train/val sizes, and folder where masks located"
      ],
      "metadata": {
        "id": "WeZh61BJFrnU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dNNloXvfB6vS"
      },
      "outputs": [],
      "source": [
        "# name of DB\n",
        "DB = 'coverage'\n",
        "# COVERAGE is a very small DB\n",
        "val_size = test_size = 15\n",
        "# name \n",
        "files = 'masks'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dh1y1xHDV4g"
      },
      "source": [
        "### IEEE IFS-TC ImageForensics Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct zip upload:"
      ],
      "metadata": {
        "id": "EWz-AVJ6Df92"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-UQH4sz4ga9"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(root +'fake 2.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeqRNokZFHke"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(root + 'pristine.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read DB files from Drive directly (faster)"
      ],
      "metadata": {
        "id": "wSiF_3oODkdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path where images and masks folder(s) are located \n",
        "db_root = '/content/drive/MyDrive/IF_DBs/IFS-TC/'"
      ],
      "metadata": {
        "id": "O4umE_e652bV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9mLU0W8jXLgH"
      },
      "outputs": [],
      "source": [
        "# name of DB\n",
        "DB = 'ifs-tc'\n",
        "# COVERAGE is a very small DB\n",
        "val_size = test_size = 150\n",
        "# name \n",
        "files = 'fake'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Cj8DulDdHQ"
      },
      "source": [
        "### other constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IkQAZr8dCQLn"
      },
      "outputs": [],
      "source": [
        "# YOLO requires images to be squares \n",
        "# choose appropriate side length\n",
        "im_size = 416"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf /content/current\n",
        "%mkdir /content/current"
      ],
      "metadata": {
        "id": "oqhhrgD1bqBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/current/'"
      ],
      "metadata": {
        "id": "HgMqIJvB_Rdl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_PfvUxx6RZ6N"
      },
      "outputs": [],
      "source": [
        "# Create Labeled Train/Val/Test Sets in Proper File Structure\n",
        "# train \n",
        "os.mkdir(root + 'train')\n",
        "os.mkdir(root + 'train/' + 'labels')\n",
        "os.mkdir(root + 'train/' + 'images')\n",
        "# test\n",
        "os.mkdir(root + 'test')\n",
        "os.mkdir(root + 'test/' + 'labels')\n",
        "os.mkdir(root + 'test/' + 'images')\n",
        "# valid\n",
        "os.mkdir(root + 'valid')\n",
        "os.mkdir(root + 'valid/' + 'labels')\n",
        "os.mkdir(root + 'valid/' + 'images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEmATOhQUvbW"
      },
      "source": [
        "## Create and label synthetic Tampered Dataset (and divide into train/valid)\n",
        "- either save the weights (trained with synthetic data) to retrain or fine-tune with non-synthetic dataset or run add them to the same training set\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR1zChvkE-Qa"
      },
      "source": [
        "## TODO:\n",
        "\n",
        "Datasets:\n",
        "- try other image fraud db\n",
        "- compare synthetic Pascal Voc images (download masks)\n",
        "- compare synthetic COCO images (download masks)\n",
        "\n",
        "Testing:\n",
        "- add in untampered images\n",
        "- add more augmented data from actual training set since there is a class imbalance\n",
        "\n",
        "Preprossing:\n",
        "- try resizing via padding only to avoid adding additional \"tampering\" or artifacts\n",
        "- move around masks pasted\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yctfXcRaM1Uv"
      },
      "source": [
        "##image fraud DBs only include masks (no BBs) so this `createLabeledSets` function extracts BBs from masks to create the labels while placing properly formatted images and labels in proper YOLO file structures (for each train/val/test set)\n",
        "\n",
        "\n",
        "**root:** where directories with test/train/val will be created \n",
        "and where the original tampered/authentic images and masks will be unzipped\n",
        "\n",
        "**DB:** name of image fraud database\n",
        "\n",
        "**files:** name of folder holding all masks and/or corresponding tampered images\n",
        "\n",
        "**test_size:** number of test images\n",
        "\n",
        "**val_size:** number of validation images\n",
        "\n",
        "**im_size:** side length of square images\n",
        "\n",
        "**synthetic:** if True then a synthetically crop object from another image and paste onto untampered image\n",
        "\n",
        "**num_real** = number of real (authentic) images to add to the training test and validation sets\n",
        "**augmentation** = 'None'\n",
        "**n_rotations** = 1\n",
        "**bb_pad** = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7tsvQms1UyDU"
      },
      "outputs": [],
      "source": [
        "def createLabeledSets(root, DB, files, test_size, val_size, im_size, synthetic, num_real = 0, augmentation = 'None', n_rotations = 1, bb_pad = 0):\n",
        "\n",
        "  # get all mask names in a list (sorted so first images will always be in test set)\n",
        "  all_files = list(sorted(os.listdir(os.path.join(db_root, files))))\n",
        "\n",
        "  subset = 'test'\n",
        "  count = num_real\n",
        "  group = ['test', 'train', 'valid']\n",
        "\n",
        "  # def crop_resize(im, im_size, bb = None):\n",
        "  #   if bb != None:\n",
        "  #     x0, x0, w, h = bb\n",
        "  #     # amount to subtract from each coordinate x and y of the topleft corner of the BB to get new image corner\n",
        "  #     d_x, d_y = randint( 0, min(x0, im_size-w)), randint(0, min(y0, im_size-h)) \n",
        "    \n",
        "  #     new_im = im[x0 - d_x: ]\n",
        "\n",
        "  # iterate through each mask \n",
        "  for i in range(len(all_files)):\n",
        "    \n",
        "    if test_size <= i < (test_size + val_size):\n",
        "      subset = 'valid' \n",
        "    elif i >= (test_size + val_size):\n",
        "      subset = 'train'\n",
        "\n",
        "    if i < test_size:\n",
        "      num = randint(0,test_size)\n",
        "    else:\n",
        "      num = randint(test_size,len(all_files)-1)\n",
        "\n",
        "    if DB == 'coverage':\n",
        "      ext = '.jpeg'\n",
        "      rev = False\n",
        "      mode = cv2.THRESH_BINARY\n",
        "      # remove forgery type info from image number so it matches with the corresponding image\n",
        "      # for COVERAGE dataset matching numbers in names mean corresponding image/mask pair\n",
        "      auth_name = re.sub(\"[^0-9]\", \"\", all_files[i])\n",
        "      \n",
        "      if all_files[i] != auth_name + 'paste.jpeg':\n",
        "        continue\n",
        "\n",
        "      tamp_name = auth_name + 't' \n",
        "      # make sure to not paste on tampered image for synthetic generation\n",
        "      auth2_name = re.sub(\"[^0-9]\", \"\", all_files[num]) \n",
        "\n",
        "      # get image and mask using above\n",
        "      tamp_im_i = cv2.imread(os.path.join(db_root, \"images\", tamp_name + ext))\n",
        "      mask_im_i = cv2.imread(os.path.join(db_root, files, all_files[i]))\n",
        "      # COVERAGE contains a corresponding 'real' image for each tampered image\n",
        "      auth_im = cv2.imread(os.path.join(db_root, \"images\", auth_name + ext))\n",
        "      auth2_im = cv2.imread(os.path.join(db_root, \"images\", auth2_name + ext)) \n",
        "    \n",
        "    if DB == 'ifs-tc':\n",
        "      ext = '.png'\n",
        "      rev = True\n",
        "      mode = cv2.THRESH_BINARY_INV\n",
        "      if all_files[i] == all_files[i].split('.mask')[0]:\n",
        "        continue\n",
        "      tamp_name = all_files[i].split('.mask')[0]\n",
        "      auth_name = list(sorted(os.listdir(os.path.join(db_root, 'pristine'))))[i].split(ext)[0]#all_files[i].split(ext)[0]\n",
        "      auth2_name = list(sorted(os.listdir(os.path.join(db_root, 'pristine'))))[num].split(ext)[0]\n",
        "\n",
        "      tamp_im_i = cv2.imread(os.path.join(db_root, files, tamp_name + ext))\n",
        "      mask_im_i = cv2.imread(os.path.join(db_root, files, all_files[i]))\n",
        "      auth_im = cv2.imread(os.path.join(db_root, \"pristine\", auth_name + ext)) \n",
        "      auth2_im = cv2.imread(os.path.join(db_root, \"pristine\", auth2_name + ext)) \n",
        "\n",
        "\n",
        "    if num_real > 0 and count > 0:\n",
        "        count -= 1\n",
        "        subset2 = group[i % 3]\n",
        "        # write empty file meaning 'no object' for untampered images (ones without the 't' are untampered)\n",
        "        with open(os.path.join(root, subset2, \"labels\", auth_name + '.txt'), 'w') as f:     \n",
        "          f.write(' ')\n",
        "        # then add the real image to the set folder\n",
        "\n",
        "        ### HERE\n",
        "        auth_im = cv2.resize(auth_im, (im_size,im_size))\n",
        "        cv2.imwrite(os.path.join(root, subset2, \"images\", auth_name + ext), auth_im)\n",
        "      \n",
        "\n",
        "    for j in range(n_rotations):\n",
        "      mask_im = mask_im_i\n",
        "      tamp_im = tamp_im_i\n",
        "      # rotate both the mask and the tamped image its extracted from \n",
        "      if j == 0:\n",
        "        # no rotation (full 360)\n",
        "        mask_im = cv2.rotate(mask_im, cv2.ROTATE_180)\n",
        "        tamp_im = cv2.rotate(tamp_im, cv2.ROTATE_180)\n",
        "        rotate = cv2.ROTATE_180\n",
        "      elif j == 1:\n",
        "        if subset == 'test':\n",
        "          break\n",
        "        rotate = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
        "      elif j == 2:\n",
        "        rotate = cv2.ROTATE_180\n",
        "      else:\n",
        "        rotate = cv2.ROTATE_90_CLOCKWISE\n",
        "      \n",
        "      # get BBs from mask\n",
        "      # first rotate and resize\n",
        "   \n",
        "      mask_im = cv2.rotate(mask_im, rotate)\n",
        "      ### HERE\n",
        "      mask_im = cv2.resize(mask_im, (im_size, im_size))\n",
        "\n",
        "      # make sure image is binary and threshold\n",
        "      gray = cv2.cvtColor(mask_im, cv2.COLOR_BGR2GRAY)\n",
        "      thresh = cv2.threshold(gray,250,255, mode)[1]\n",
        "      cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "      for c in cnts:\n",
        "        x, y, w1, h1 = cv2.boundingRect(c)\n",
        "      if x + w1 >= im_size:\n",
        "        continue\n",
        "      if y + h1 >= im_size:\n",
        "        continue        \n",
        "      # YOLO requires coordinates in x,y center, x,y height/width\n",
        "      c_x = x + (w1 // 2) \n",
        "      c_y = y + (h1 // 2)\n",
        "      # YOLO requires normalization of coordinates      \n",
        "      c_x /= im_size\n",
        "      c_y /= im_size \n",
        "      w = (w1 + bb_pad) / im_size \n",
        "      h = (h1 + bb_pad)/ im_size\n",
        "\n",
        "      # rotate and resize image (same ask mask)\n",
        "      im_r = cv2.rotate(tamp_im, rotate)\n",
        "\n",
        "      ### HERE\n",
        "      out_im = cv2.resize(im_r, (im_size,im_size))\n",
        "\n",
        "      if synthetic == True:  \n",
        "        # read in random image to paste extracted masked region onto it\n",
        "        # and keep BG and FG images in same sets:\n",
        "\n",
        "        ### HERE\n",
        "        auth2_im = cv2.resize(auth2_im, (im_size, im_size))\n",
        "      \n",
        "        # mask of im is 0/black or white\n",
        "        # (depending on DB) everywhere where im2 will go   \n",
        "        if rev == True:\n",
        "          out_im = np.where(mask_im == 0, out_im, auth2_im)\n",
        "        else:\n",
        "          out_im = np.where(mask_im == 0, auth2_im, out_im)\n",
        "        # im = np.where(mask >= 250, im, im2)\n",
        "\n",
        "      if augmentation != 'None':\n",
        "        # imagaug and albumentations (augmentations for BB included)\n",
        "        if subset == 'test':\n",
        "          break\n",
        "        if augmentation == 'brightness':\n",
        "          b = np.ones(out_im.shape, dtype='uint8')*70\n",
        "          out_im = cv2.add(out_im,b)\n",
        "\n",
        "        elif augmentation == 'dullness':\n",
        "          d = np.ones(out_im.shape, dtype='uint8')*70\n",
        "          out_im = cv2.subtract(out_im,d)\n",
        "\n",
        "        elif augmentation == 'sharpness':\n",
        "          s = np.array([[-1,-1,-1],[-1,10,-1],[-1,-1,-1]])\n",
        "          out_im = cv2.filter2D(out_im, -1,s)\n",
        "\n",
        "      # debug:\n",
        "      #out_im = cv2.rectangle(out_im, (x- (bb_pad//2),y- (bb_pad//2)), (x+w1 + (bb_pad//2),y+h1+ (bb_pad//2)), (255, 255, 255), 2)\n",
        "      \n",
        "      cv2.imwrite(os.path.join(root, subset, \"images\", tamp_name + '_' + augmentation + str(j) + ext), out_im)\n",
        "\n",
        "      with open(os.path.join(root, subset, \"labels\", tamp_name + '_' + augmentation + str(j) + '.txt'), 'w') as f:\n",
        "        f.write(str(0) + ' ' + str(c_x) + ' ' + str(c_y) + ' ' + str(w) + ' ' + str(h))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOdsGY5HU4cE"
      },
      "source": [
        "## Label actual Tampered Dataset (and divide into test/train/valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### synthetic db all 4 rotations and 2 augmentation types"
      ],
      "metadata": {
        "id": "9MMdPL6SSgL-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Nrgt9LhNUxf_"
      },
      "outputs": [],
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, True, 0, 'None', 4, 4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, True, 0, 'dullness', 1, 10)"
      ],
      "metadata": {
        "id": "gi6i_OS2IqVb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, True, 0, 'brightness', 1, 10)"
      ],
      "metadata": {
        "id": "oa2ivqB4IrjP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVJJdlQ2YUai"
      },
      "source": [
        "### Create sets (non-synthetic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnmB7DCb2y0"
      },
      "outputs": [],
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, False, 0, 'None', 4, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ih5LzxiljJ3"
      },
      "outputs": [],
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, False, 0, 'brightness', 1, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av2lIOnNlqIA"
      },
      "outputs": [],
      "source": [
        "createLabeledSets(root, DB, files, test_size, val_size, im_size, False, 0, 'dullness', 1, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQAETqIVDZN",
        "outputId": "92baf6f4-c5c9-43c4-e9da-b67b055b902d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/data.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/data.yaml\n",
        "train: /content/current/train/images\n",
        "val: /content/current/valid/images\n",
        "test: /content/current/test/images\n",
        "\n",
        "\n",
        "nc: 1\n",
        "names: ['tampered']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "2822fbc3-2a80-4cae-f0c1-4d2688848353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 üöÄ v6.2-23-g4a8ab3b Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ‚úÖ (4 CPUs, 25.5 GB RAM, 40.6/166.8 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "#import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5e4zFticKEB"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 240 --data '/content/data.yaml' --cfg /content/yolov5/models/yolov5m.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vrE2RPn4jPf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a67b05-1079-41d6-9938-14be95199852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/data.yaml, weights=['/content/yolov5/runs/train/yolov5s_results2/weights/best.pt'], batch_size=32, imgsz=416, conf_thres=0.5, iou_thres=0.6, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "WARNING: confidence threshold 0.5 > 0.001 produces invalid results ‚ö†Ô∏è\n",
            "YOLOv5 üöÄ v6.2-23-g4a8ab3b Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5m summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/current/test/labels.cache' images and labels... 59 found, 0 missing, 0 empty, 0 corrupt: 100% 59/59 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.52it/s]\n",
            "                 all         59         59      0.395      0.288      0.334      0.254\n",
            "Speed: 0.1ms pre-process, 3.8ms inference, 1.4ms NMS per image at shape (32, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n",
            "33 labels saved to runs/val/exp2/labels\n",
            "CPU times: user 91.1 ms, sys: 26.2 ms, total: 117 ms\n",
            "Wall time: 10.5 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python val.py --weights /content/yolov5/runs/train/yolov5s_results2/weights/best.pt --data /content/data.yaml --img 416 --conf 0.5 --task test --save-txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5/classify/\n",
        "!python predict.py --weights /content/yolov5/runs/train/yolov5s_results2/weights/best.pt \n"
      ],
      "metadata": {
        "id": "Pzmj9YcxvyV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPYFCKzek6Cp"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results2/weights/best.pt --img 416 --conf 0.2 --source ../current/test/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v_ye08udHeL"
      },
      "source": [
        "## Freeze backbone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdmCRg3bVh5e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --freeze 10 --img 416 --batch 16 --epochs 240 --data '/content/data.yaml' --cfg /content/yolov5/models/yolov5m.yaml --weights '/content/syn240.pt' --name yolov5s_results  --cache"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Coverage+Synthetic+Yolo",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}